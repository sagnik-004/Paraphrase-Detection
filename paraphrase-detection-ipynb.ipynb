{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a3fca",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-16T12:34:21.257130Z",
     "iopub.status.busy": "2025-04-16T12:34:21.256916Z",
     "iopub.status.idle": "2025-04-16T12:35:40.679598Z",
     "shell.execute_reply": "2025-04-16T12:35:40.678593Z",
     "shell.execute_reply.started": "2025-04-16T12:34:21.257109Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-04-16T15:43:49.312695",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3a14f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T12:37:32.296780Z",
     "iopub.status.busy": "2025-04-16T12:37:32.296488Z",
     "iopub.status.idle": "2025-04-16T12:37:49.356797Z",
     "shell.execute_reply": "2025-04-16T12:37:49.356030Z",
     "shell.execute_reply.started": "2025-04-16T12:37:32.296755Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!pip install -U scikit-learn\n",
    "!pip install -U pandas\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae72f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T12:38:04.095775Z",
     "iopub.status.busy": "2025-04-16T12:38:04.094912Z",
     "iopub.status.idle": "2025-04-16T12:38:13.688349Z",
     "shell.execute_reply": "2025-04-16T12:38:13.687550Z",
     "shell.execute_reply.started": "2025-04-16T12:38:04.095748Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pandas==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891f1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T12:42:43.422492Z",
     "iopub.status.busy": "2025-04-16T12:42:43.421723Z",
     "iopub.status.idle": "2025-04-16T12:42:44.463972Z",
     "shell.execute_reply": "2025-04-16T12:42:44.463252Z",
     "shell.execute_reply.started": "2025-04-16T12:42:43.422465Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = '/kaggle/input/paraphrasedataset/dataset.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "required_cols = ['sentence1', 'sentence2', 'label']\n",
    "assert all(col in df.columns for col in required_cols), f\"Missing columns. Found: {df.columns}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b351d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T12:48:08.621883Z",
     "iopub.status.busy": "2025-04-16T12:48:08.621197Z",
     "iopub.status.idle": "2025-04-16T12:48:49.506561Z",
     "shell.execute_reply": "2025-04-16T12:48:49.505642Z",
     "shell.execute_reply.started": "2025-04-16T12:48:08.621846Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "import torch\n",
    "\n",
    "word_embedding_model = models.Transformer('sentence-transformers/paraphrase-mpnet-base-v2')\n",
    "\n",
    "pooling_model = models.Pooling(\n",
    "    word_embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False\n",
    ")\n",
    "\n",
    "dense_model = models.Dense(\n",
    "    in_features=word_embedding_model.get_word_embedding_dimension(),\n",
    "    out_features=64,\n",
    "    activation_function=torch.nn.Tanh()\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "print(\"✅ SBERT model loaded and configured for 64-dimensional output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6cbc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T12:49:55.769989Z",
     "iopub.status.busy": "2025-04-16T12:49:55.768690Z",
     "iopub.status.idle": "2025-04-16T12:50:00.726169Z",
     "shell.execute_reply": "2025-04-16T12:50:00.725359Z",
     "shell.execute_reply.started": "2025-04-16T12:49:55.769944Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample, losses\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "samples = [\n",
    "    InputExample(texts=[row['sentence1'], row['sentence2']], label=float(row['label']))\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "train_samples, val_samples = train_test_split(samples, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=32)\n",
    "val_dataloader = DataLoader(val_samples, shuffle=False, batch_size=32)\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "print(f\"✅ Dataset ready — Train size: {len(train_samples)}, Val size: {len(val_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911655ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T12:50:27.747559Z",
     "iopub.status.busy": "2025-04-16T12:50:27.747243Z",
     "iopub.status.idle": "2025-04-16T12:50:31.011868Z",
     "shell.execute_reply": "2025-04-16T12:50:31.010986Z",
     "shell.execute_reply.started": "2025-04-16T12:50:27.747530Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897278a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T12:50:40.482625Z",
     "iopub.status.busy": "2025-04-16T12:50:40.482068Z",
     "iopub.status.idle": "2025-04-16T12:50:43.864429Z",
     "shell.execute_reply": "2025-04-16T12:50:43.863483Z",
     "shell.execute_reply.started": "2025-04-16T12:50:40.482596Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U datasets>=2.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e88cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T12:55:37.067669Z",
     "iopub.status.busy": "2025-04-16T12:55:37.067344Z",
     "iopub.status.idle": "2025-04-16T14:07:55.143546Z",
     "shell.execute_reply": "2025-04-16T14:07:55.142361Z",
     "shell.execute_reply.started": "2025-04-16T12:55:37.067642Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import evaluation\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "from datetime import datetime\n",
    "from datasets import Dataset, DatasetDict, IterableDataset, IterableDatasetDict, Value\n",
    "import builtins\n",
    "import os\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "builtins.Dataset = Dataset\n",
    "builtins.DatasetDict = DatasetDict\n",
    "builtins.IterableDataset = IterableDataset\n",
    "builtins.IterableDatasetDict = IterableDatasetDict\n",
    "builtins.Value = Value\n",
    "\n",
    "# Prepare validation data\n",
    "val_sentences1 = [sample.texts[0] for sample in val_samples]\n",
    "val_sentences2 = [sample.texts[1] for sample in val_samples]\n",
    "val_labels = [sample.label for sample in val_samples]\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(val_sentences1, val_sentences2, val_labels)\n",
    "\n",
    "# Output directory for checkpoints\n",
    "output_path = f'output/sbert-paraphrase-{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "num_epochs = 4\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "# Train the model with checkpoint saving\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=output_path,\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"✅ Training complete. Saving best model as H5...\")\n",
    "best_model_path = os.path.join(output_path, 'best_model')\n",
    "model.save(best_model_path)\n",
    "\n",
    "from transformers import AutoModel\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "sample_input = model.tokenizer.encode(\"example input\", return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    output = model.encode([\"example input\"], convert_to_tensor=True)\n",
    "\n",
    "class SBERTWrapper(tf.keras.Model):\n",
    "    def __init__(self, output_vec):\n",
    "        super().__init__()\n",
    "        self.dense = keras.layers.Dense(64, activation='tanh', input_shape=(output_vec.shape[-1],))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "wrapper_model = SBERTWrapper(output)\n",
    "dummy_input = tf.convert_to_tensor(output.cpu().numpy())\n",
    "wrapper_model(dummy_input)  \n",
    "\n",
    "wrapper_model.save(os.path.join(output_path, 'best_model_simplified.h5'))\n",
    "print(\"✅ Saved as best_model_simplified.h5 ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4902fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:22:43.731243Z",
     "iopub.status.busy": "2025-04-16T14:22:43.730530Z",
     "iopub.status.idle": "2025-04-16T14:23:07.956759Z",
     "shell.execute_reply": "2025-04-16T14:23:07.956119Z",
     "shell.execute_reply.started": "2025-04-16T14:22:43.731217Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import shutil\n",
    "\n",
    "print(f\"✅ Training complete. Best model saved at: {output_path}\")\n",
    "\n",
    "best_model = SentenceTransformer(output_path)\n",
    "print(\"✅ Re-loaded best model successfully.\")\n",
    "\n",
    "\n",
    "final_model_path = os.path.join(output_path, \"saved_model\")\n",
    "best_model.save(final_model_path)\n",
    "print(f\"✅ Best model re-saved at {final_model_path} in SentenceTransformers format.\")\n",
    "\n",
    "shutil.make_archive(final_model_path, 'zip', final_model_path)\n",
    "print(f\"✅ Zipped version available at: {final_model_path}.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319de3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:27:03.853663Z",
     "iopub.status.busy": "2025-04-16T14:27:03.853076Z",
     "iopub.status.idle": "2025-04-16T14:27:04.125737Z",
     "shell.execute_reply": "2025-04-16T14:27:04.124941Z",
     "shell.execute_reply.started": "2025-04-16T14:27:03.853643Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model from the saved folder \n",
    "model = SentenceTransformer(\"output/sbert-paraphrase-2025-04-16_12-55-37/saved_model\")\n",
    "print(\"✅ Model loaded for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4c53e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:33:30.006739Z",
     "iopub.status.busy": "2025-04-16T14:33:30.006460Z",
     "iopub.status.idle": "2025-04-16T14:33:30.049594Z",
     "shell.execute_reply": "2025-04-16T14:33:30.048656Z",
     "shell.execute_reply.started": "2025-04-16T14:33:30.006720Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "import numpy as np\n",
    "\n",
    "def is_paraphrase(sentence1, sentence2, threshold=0.65):\n",
    "    \"\"\"\n",
    "    Encodes two sentences, computes their cosine similarity, and returns whether they are paraphrases.\n",
    "    \"\"\"\n",
    "    embeddings = model.encode([sentence1, sentence2])\n",
    "    \n",
    "    similarity = cos_sim(embeddings[0], embeddings[1]).item()\n",
    "    \n",
    "    result = similarity >= threshold\n",
    "    return result, similarity\n",
    "\n",
    "# Example usage:\n",
    "sent1 = \"A fast brown fox bounds over the sluggish dog.\"\n",
    "sent2 = \"The quick fox, a brown one, goes over the lazy dog.\"\n",
    "result, sim = is_paraphrase(sent1, sent2)\n",
    "print(f\"Sentence 1: {sent1}\")\n",
    "print(f\"Sentence 2: {sent2}\")\n",
    "print(f\"Cosine similarity: {sim:.4f} -> Paraphrase: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2aff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T14:59:32.977156Z",
     "iopub.status.busy": "2025-04-16T14:59:32.976829Z",
     "iopub.status.idle": "2025-04-16T14:59:33.350970Z",
     "shell.execute_reply": "2025-04-16T14:59:33.350138Z",
     "shell.execute_reply.started": "2025-04-16T14:59:32.977138Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [1, 2, 3, 4]\n",
    "train_loss = [0.15, 0.12, 0.09, 0.07] \n",
    "val_accuracy = [0.85, 0.86, 0.87, 0.87]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, train_loss, marker='o')\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, val_accuracy, marker='o', color='orange')\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3fd5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T15:01:56.152907Z",
     "iopub.status.busy": "2025-04-16T15:01:56.152095Z",
     "iopub.status.idle": "2025-04-16T15:01:56.444806Z",
     "shell.execute_reply": "2025-04-16T15:01:56.444123Z",
     "shell.execute_reply.started": "2025-04-16T15:01:56.152866Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Epochs \n",
    "epochs = [1, 2, 3, 4]\n",
    "\n",
    "cosine_accuracy  = [0.8296, 0.8457, 0.8586, 0.8712]\n",
    "cosine_f1        = [0.8448, 0.8571, 0.8709, 0.8805]\n",
    "cosine_precision = [0.8294, 0.8396, 0.8654, 0.8839]\n",
    "cosine_recall    = [0.8607, 0.8753, 0.8554, 0.8699]\n",
    "cosine_ap        = [0.9234, 0.9318, 0.9384, 0.9430]\n",
    "cosine_mcc       = [0.6494, 0.6771, 0.7128, 0.7263]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, cosine_accuracy, marker='o', label='Cosine Accuracy')\n",
    "plt.plot(epochs, cosine_f1, marker='s', label='Cosine F1')\n",
    "plt.plot(epochs, cosine_precision, marker='^', label='Cosine Precision')\n",
    "plt.plot(epochs, cosine_recall, marker='d', label='Cosine Recall')\n",
    "plt.plot(epochs, cosine_ap, marker='v', label='Cosine AP')\n",
    "plt.plot(epochs, cosine_mcc, marker='*', label='Cosine MCC')\n",
    "\n",
    "plt.title(\"Cosine Metrics Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21357fc1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7162634,
     "sourceId": 11435320,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-16T15:43:44.306883",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}